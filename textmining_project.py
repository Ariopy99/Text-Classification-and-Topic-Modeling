# -*- coding: utf-8 -*-
"""TextMining_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LMMVWx8-0MNhFh787VT7JdGOVmJGGGFx

# Text Mining Project - PubMed 20K DataSet

The dataset chosen is a reduced version of the PubMed 200K RCT Dataset, consisitng in 10% of the observations.

First step is to mount the google drive where the files have been stored and import the data
"""

import pandas as pd
from google.colab import drive
import numpy as np
import matplotlib.pyplot as plt

drive.mount('/content/drive')
file_path = '/content/drive/MyDrive/PubMed.csv'
data = pd.read_csv(file_path, sep=',')

data.head(15)

data.shape

"""The dataset has a total of 180040 instances and 6 variables, where the variable **Target** is the class variable"""

data.info()

"""As we can assess from the *info()* there are not NaN values in the dataset."""

data['target'].value_counts()

"""The **Target** variable is a multi-class variable consisting of 5 different classes:

- METHODS:
- RESULTS:
- CONCLUSIONS:
- BACKGROUND:
- OBJECTIVE:
"""

def percent_class(classe):
  return data[data['target']==classe].count()['target']/data.shape[0]*100

percentuali = {}
for i in data['target'].unique():
  percentuali[i] = percent_class(i)


fig, ax = plt.subplots()

fig.set_facecolor('black')
ax.set_facecolor('black')

wedges, texts, autotexts = ax.pie(
    percentuali.values(),
    labels=percentuali.keys(),
    autopct='%1.1f%%',
    colors=['#2d5f5e', '#4fffd3', '#7fbdde', '#bea8df', '#d143f2'],
    textprops={'color': 'white'}
)

for autotext in autotexts:
    autotext.set_color('black')

plt.title('Target Classes Distribution', color='white')
plt.savefig('piechart.png')
plt.show()

data['text_length'] = data['abstract_text'].apply(lambda x: len(x))
def count_words(text):
    return len(text.split())
data['word_count'] = data['abstract_text'].apply(count_words)

data.groupby('target').agg({'text_length': 'mean','word_count': 'mean'}).sort_values(by='text_length', ascending=False)

data['abstract_id'].nunique()

"""The total number of different scientific papers is 15000

## Pre-Processing
"""

import nltk
import re
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import WordPunctTokenizer
import string
nltk.download('stopwords')
nltk.download('wordnet')
stop_words = nltk.corpus.stopwords.words('english')
wnl = WordNetLemmatizer()

"""We define a function that gives the POS tagging of each word, to ensure a good performance of the lemmatizer when applied to the corpus text."""

from nltk.corpus import wordnet
nltk.download('averaged_perceptron_tagger_eng')

def get_wordnet_pos(word):
    """Map POS tag to first character lemmatize() accepts."""
    tag = nltk.pos_tag([word])[0][1]  # POS tagging
    if tag.startswith('V'):
        return wordnet.VERB
    elif tag.startswith('N'):
        return wordnet.NOUN
    elif tag.startswith('R'):
        return wordnet.ADV
    else:
        return wordnet.ADJ

"""**Pre-Prcessing function**:

The fundamental steps for text pre-processing are:

- Remove punctuation
- Remove numbers
- Tokenize the text
- Remove the stop words
- Leammtize the tokens
"""

def preprocessing(text):
    text = re.sub(r'\bp-value\b', 'p_value', text)  # Substitute "p-value" with "p_value" to make that as a unique token
    text = re.sub(r'(\b\w+)-(\w+\b)', r'\1 \2', text) # Substitite words separated by '-' with a space

    punctuationfree = text.translate(str.maketrans('', '', string.punctuation))  # Remove punctuation

    nonumbers = re.sub(r'\d+', '', punctuationfree)  # Remove numbers

    tokenized_text = WordPunctTokenizer().tokenize(nonumbers) # Tokenize the corpus

    tokenized_text_without_stopwords = [w for w in tokenized_text if w.lower() not in stop_words] # Remove the stop words

    tokens = [wnl.lemmatize(w, pos=get_wordnet_pos(w)) for w in tokenized_text_without_stopwords] # Lemmatize using the POS tagging for a better performance

    return tokens

"""Apply the pre-prcessing function creating a new column in the data frame, called *tokens*"""

data['tokens'] = data['abstract_text'].apply(lambda x: preprocessing(x))

data['cleaned']=data['tokens'].apply(lambda x: ' '.join([i for i in x if i not in string.punctuation]))

data.head(8)

print('The row text is:',data['abstract_text'][0])
print('The tokenized text is:', data['tokens'][0])

"""## Text Classification

Division of the entire dataset into test and training, respectively 20% and 80% of the original datset.
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(data['cleaned'], data['target'], test_size=0.2, random_state=42)

"""### Vectorization: Tf - Idf"""

from sklearn.feature_extraction.text import TfidfVectorizer
vectorizer = TfidfVectorizer(stop_words=None, max_df=0.75,lowercase=True, min_df=50)
X_train_vec = vectorizer.fit_transform(X_train)
X_test_vec = vectorizer.transform(X_test)

X_train_vec.shape

X_train_vec.nnz/float(X_train_vec.shape[0]*X_train_vec.shape[1])

"""### Classifiers: training and evaluation"""

from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report, precision_score

"""#### Logstic Regression"""

clf_LR = LogisticRegression(max_iter=500)
clf_LR.fit(X_train_vec, y_train)
y_pred_LR = clf_LR.predict(X_test_vec)

print(classification_report(y_test, y_pred_LR))

"""#### Decision Tree"""

clf = DecisionTreeClassifier().fit(X_train_vec, y_train)
y_pred_DT = clf.predict(X_test_vec)

print(classification_report(y_test, y_pred_DT))

"""#### Random Forest"""

clf_RF = RandomForestClassifier(random_state=100).fit(X_train_vec, y_train)
y_pred_RF = clf_RF.predict(X_test_vec)

print(classification_report(y_test, y_pred_RF))

"""#### Multinomial Naive Bayes"""

clf_NB = MultinomialNB().fit(X_train_vec, y_train)
y_pred_NB = clf_NB.predict(X_test_vec)

print(classification_report(y_test, y_pred_NB))

"""#### Support Vector Machine

Due to computational expensivity, we trained the Support Vector Machine on a reduced data set, composed of about 50% of the observations in the original dataset:

- 70000 instances from the training set
- 10000 instances from the test set
"""

sample_train=X_train_vec[:70000]
sample_test=X_test_vec[:10000]

clf_SVC = SVC().fit(sample_train, y_train[:70000])
y_pred_SVC = clf_SVC.predict(sample_test)

print(classification_report(y_test[:10000], y_pred_SVC))

"""### Visualization of the evaluation metrics

To have a more immediate confront between the classifiers trained, we can visualize the evaluation metrics in a line plot for each classifier
"""

classifiers = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'Multinomial Naive Bayes', 'Support Vector Machine']
acc_scores = [accuracy_score(y_test, y_pred_LR), accuracy_score(y_test, y_pred_DT), accuracy_score(y_test, y_pred_RF), accuracy_score(y_test, y_pred_NB), accuracy_score(y_test[:10000], y_pred_SVC)]
f1_scores = [f1_score(y_test, y_pred_LR, average='weighted'), f1_score(y_test, y_pred_DT, average='weighted'), f1_score(y_test, y_pred_RF, average='weighted'), f1_score(y_test, y_pred_NB, average='weighted'), f1_score(y_test[:10000], y_pred_SVC, average='weighted')]
rec_scores = [recall_score(y_test, y_pred_LR, average='weighted'), recall_score(y_test, y_pred_DT, average='weighted'), recall_score(y_test, y_pred_RF, average='weighted'), recall_score(y_test, y_pred_NB, average='weighted'),recall_score(y_test[:10000], y_pred_SVC, average='weighted')]
prec_scores = [precision_score(y_test, y_pred_LR, average='weighted'), precision_score(y_test, y_pred_DT, average='weighted'), precision_score(y_test, y_pred_RF, average='weighted'), precision_score(y_test, y_pred_NB, average='weighted'),precision_score(y_test[:10000], y_pred_SVC, average='weighted')]

colors = ['red', 'green', 'orange', 'blue', 'purple']
plt.figure(figsize=(10, 6))

for i, clf in enumerate(classifiers):
    plt.plot(['Accuracy', 'Recall','Precision','F1-score'], [acc_scores[i], rec_scores[i],
                                                 prec_scores[i], f1_scores[i]], marker='o', label=clf, color=colors[i])


plt.xlabel('Evaluation Metrics')
plt.ylabel('Values')
plt.title('Metric for each classifier')
plt.legend(title='Classifiers')

plt.savefig('performances_class3.png', format='png')
plt.show()

class_names = ['METHODS', 'RESULTS', 'CONCLUSIONS', 'BACKGROUND', 'OBJECTIVE']

import seaborn as sns
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test[:10000], y_pred_SVC)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix Heatmap - SVC')
plt.savefig('confusion_matrix_SVC.png', format='png')
plt.show()

cm = confusion_matrix(y_test, y_pred_LR)
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', xticklabels=class_names, yticklabels=class_names)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix Heatmap - Logistic Regression')
plt.savefig('confusion_matrix_LR.png', format='png')
plt.show()

"""# Topic Modeling

To perform topic modeling, we grouped the abstract of the documents, resulting in the complete abstract for each of teh 15000 scientific papers which compose the dataset.
"""

newdata = data.groupby('abstract_id').agg({'tokens': 'sum','cleaned':'sum', 'abstract_text':'sum'}).reset_index()
newdata.head()

pip install pyLDAvis

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
import gensim
import numpy as np
import spacy

from gensim.models import CoherenceModel, LdaModel, LsiModel, HdpModel
from gensim.corpora import Dictionary

from sklearn.metrics.pairwise import cosine_similarity

import pyLDAvis.gensim

import os, re, operator, warnings
warnings.filterwarnings('ignore')
# %matplotlib inline

texts = newdata['tokens']

dictionary = Dictionary(texts) # Create the dictionary on the previously tokens

"""Perform a filtering on the dictionary to pass uninfluent words, we keep those that:

- Appear in at least 5 documents
- Appear in less than 75% of documents
"""

dictionary.filter_extremes(no_below=5, no_above=0.75, keep_n=100000)

corpus = [dictionary.doc2bow(text) for text in texts] # Create the corpus to use in models

import random
texts_list = list(texts)  # Convert texts to a list if it isn't one already

# Sample 40% of the texts
sampled_texts = random.sample(texts_list, int(len(texts_list) * 0.3))

sampled_dictionary = Dictionary(sampled_texts)
sampled_dictionary.filter_extremes(no_below=5, no_above=0.75, keep_n=100000)
sampled_corpus = [sampled_dictionary.doc2bow(text) for text in sampled_texts]

len(sampled_dictionary)

"""### LSA"""

coherence_scores_LSA = []
for num_topics in range(5, 40):
    model = LsiModel(corpus=sampled_corpus, id2word=sampled_dictionary, num_topics=num_topics)
    coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')
    coherence_scores_LSA.append(coherence_model.get_coherence())

plt.figure(figsize=(8, 6))
plt.plot(range(5, 40), coherence_scores_LSA, marker='o', label='Coherence', color='#4fffd3')
plt.title('Coherence vs. Number of Topics for LSA')
plt.xlabel('Numer of topics')
plt.ylabel('Coherence score')

plt.savefig('coherence_vs_topics_LSA2.png', format='png')
plt.show()

coherence_scores_LSA

lsimodel = LsiModel(corpus=corpus, num_topics=7, id2word=dictionary)
lsimodel.show_topics(num_topics=5)

num_words = 10
for i in range(lsimodel.num_topics):
    print(f"\nTopic {i}:")
    words = lsimodel.show_topic(i, topn=num_words)
    for word, weight in words:
        print(f"  - {word} (Weight: {weight:.4f})")

from wordcloud import WordCloud

for i in range(lsimodel.num_topics):

    words = lsimodel.show_topic(i, topn=20)  # top 20 words in each topic
    word_freq = dict(words)  # Convert the list of tuples to a dictionary

    # Generate the word cloud
    wordcloud = WordCloud(width=800, height=600, background_color='white').generate_from_frequencies(word_freq)

    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(f"Word Cloud for Topic {i}")
    plt.axis('off')
    plt.show()

hdpmodel = HdpModel(corpus=corpus, id2word=dictionary, T=250,  kappa=0.8, tau=64.0 ,K=29, alpha=1, gamma=1, eta=0.01, scale=1)
hdpmodel.show_topics(num_topics=5)

"""### HDP"""

pyLDAvis.enable_notebook()
pyLDAvis.gensim.prepare(hdpmodel, corpus, dictionary)

"""### LDA Model

#### Hyperparameter Optimization: Number of topics

To determine the optimal number of topics we're going to confornt the scores of perplexity and coherence for a different number of topics.

For computational reasons, we are going to use the 30% of the texts in this estimation.
"""

coherence_scores_LDA = []
for num_topics in range(5, 40):
    model = LdaModel(corpus=sampled_corpus, id2word=sampled_dictionary, num_topics=num_topics, random_state=42, passes=5)
    coherence_model = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')
    coherence_scores_LDA.append(coherence_model.get_coherence())

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.plot(range(5, 40), coherence_scores_LDA, marker='o', label='Coherence', color='#2d5f5e')
plt.title('Coherence vs. Number of Topics for LDA')
plt.xlabel('Numer of topics')
plt.ylabel('Coherence score')

plt.savefig('coherence_vs_topics_LDA2.png', format='png')
plt.show()

coherence_scores_LDA

perplexities_LDA = []
for num_topics in range(5, 40):
    model = LdaModel(corpus=sampled_corpus, id2word=sampled_dictionary, num_topics=num_topics, random_state=42, passes=5)
    perplexities_LDA.append(model.log_perplexity(sampled_corpus))

"""'#2d5f5e', '#4fffd3', '#7fbdde', '#bea8df', '#d143f2"""

plt.figure(figsize=(8, 6))
plt.plot(range(5, 40), perplexities_LDA, marker='o', label='Perplexity', color='#d143f2')
plt.title('Perplexity vs. Number of Topics for LDA')
plt.xlabel('Numer of topics')
plt.ylabel('Perplexity score')

plt.savefig('perplexity_vs_topics_LDA.png', format='png')
plt.show()

"""LDA Model with 29 topics"""

ldamodel = LdaModel(corpus=corpus, num_topics=29, id2word=dictionary, passes=5, random_state=33)
ldamodel.show_topics(num_topics=5)

import pyLDAvis.gensim_models as gensimvis
vis_data = gensimvis.prepare(ldamodel, corpus, dictionary)
pyLDAvis.display(vis_data)

import matplotlib.pyplot as plt
from collections import Counter
import numpy as np


document_topics = [ldamodel.get_document_topics(doc) for doc in corpus]

topic_counts = Counter()
for doc in document_topics:
    for topic_id, prob in doc:
        topic_counts[topic_id] += prob


total_prob = sum(topic_counts.values())
topic_distribution = {topic_id: prob / total_prob for topic_id, prob in topic_counts.items()}

topic_ids = sorted(topic_distribution.keys())
topic_probs = [topic_distribution[tid] for tid in topic_ids]


plt.figure(figsize=(15, 6))
plt.bar([f"Topic {i}" for i in topic_ids], topic_probs, color='skyblue', alpha=0.8)
plt.xlabel('Topics')
plt.ylabel('Proportion')
plt.title('Topic Distribution in the Corpus')
plt.grid(axis='y', linestyle='--', alpha=0.7)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()


plt.tight_layout()
plt.savefig("lda_topic_distribution.png")
plt.show()

"""Word Cloud visualization for the top 20 words in each topic generated by the LDA model"""

num_words = 10
for i in range(ldamodel.num_topics):
    print(f"\nTopic {i}:")
    words = ldamodel.show_topic(i, topn=num_words)
    for word, weight in words:
        print(f"  - {word} (Weight: {weight:.4f})")

from wordcloud import WordCloud

for i in range(ldamodel.num_topics):

    words = ldamodel.show_topic(i, topn=20)  # top 20 words in each topic
    word_freq = dict(words)  # Convert the list of tuples to a dictionary

    # Generate the word cloud
    wordcloud = WordCloud(width=800, height=600, background_color='white').generate_from_frequencies(word_freq)

    plt.imshow(wordcloud, interpolation='bilinear')
    plt.title(f"Word Cloud for Topic {i}")
    plt.axis('off')
    plt.show()

# Get the dominant toic for each word
def get_dominant_topic_for_words(lda_model, dictionary, abstract_tokens):
    word_topics = {}

    for word in abstract_tokens:
        if word in dictionary.token2id:
            word_id = dictionary.token2id[word]  # Get the word ID
            topic_distribution = lda_model.get_term_topics(word_id)  # Get topics distribution for the word

            if topic_distribution:
                # Check if the word is within the vocabulary
                topic, prob = max(topic_distribution, key=lambda x: x[1])  # Find the highest probability topic
                word_topics[word] = topic  # Assign the topic to the word in the dictionary
            else:
                word_topics[word] = -1  # If the word is not the vocabulary do not assign a topic
    return word_topics

from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords

def highlight_abstract_with_topic_colors(abstract_text, word_topics):

    filtered_tokens = [w for w in abstract_text.split(' ')]

    topic_colors = plt.cm.get_cmap('tab20', ldamodel.num_topics)  # Color to each topic


    highlighted_text = ""
    for word in filtered_tokens:
        # Get topic of the words
        topic = word_topics.get(word.lower(), -1)
        if topic != -1:
            color = topic_colors(topic)  # Get color of that topic
            highlighted_text += f'<span style="color: rgb({int(color[0] * 255)}, {int(color[1] * 255)}, {int(color[2] * 255)})">{word}</span> '
        else:
            highlighted_text += f"{word} "

    return highlighted_text

from wordcloud import WordCloud
import matplotlib.pyplot as plt
from IPython.display import display, HTML

def display_highlighted_abstracts(df, lda_model, dictionary):

    for _, row in df.iterrows():
        abstract_text = row['cleaned']
        tokens = row['tokens']

        word_topics = get_dominant_topic_for_words(lda_model, dictionary, tokens)

        highlighted_abstract = highlight_abstract_with_topic_colors(abstract_text, word_topics)

        display(HTML(f"<h3>Abstract ID: {row['abstract_id']}</h3>"))
        display(HTML(f"<p>{highlighted_abstract}</p>"))

import nltk
nltk.download('punkt_tab')

newdata['abstract_text'][1]

display_highlighted_abstracts(newdata[0:5], ldamodel, dictionary)